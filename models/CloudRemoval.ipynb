{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed0b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_x = []\n",
    "filenames_y = []\n",
    "\n",
    "base_path = \"/kaggle/input/smile-cr/TrainData/TrainData\"\n",
    "\n",
    "# Use tqdm to show progress while walking directories\n",
    "for dirname, _, filenames in tqdm(os.walk(base_path), desc=\"Walking through directories\"):\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(dirname, filename)\n",
    "\n",
    "        if \"CloudLandsat_2020\" in dirname:\n",
    "            filenames_x.append(file_path)\n",
    "        elif \"Landsat-8_2020\" in dirname:\n",
    "            filenames_y.append(file_path)\n",
    "\n",
    "# Extract just the filenames (without path)\n",
    "names_x = [os.path.basename(f) for f in filenames_x]\n",
    "names_y = [os.path.basename(f) for f in filenames_y]\n",
    "\n",
    "# Sort both lists\n",
    "names_x.sort()\n",
    "names_y.sort()\n",
    "\n",
    "# Compare\n",
    "print(\"Total in X:\", len(names_x))\n",
    "print(\"Total in Y:\", len(names_y))\n",
    "\n",
    "# Show mismatches if any\n",
    "mismatches = set(names_x).symmetric_difference(set(names_y))\n",
    "if mismatches:\n",
    "    print(\"Mismatched filenames:\")\n",
    "    print(mismatches)\n",
    "else:\n",
    "    print(\"Filenames match perfectly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84f1e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_x_val = []\n",
    "filenames_y_val = []\n",
    "\n",
    "base_path = \"/kaggle/input/smile-cr/ValData/ValData\"\n",
    "\n",
    "# Use tqdm to show progress while walking directories\n",
    "for dirname, _, filenames in tqdm(os.walk(base_path), desc=\"Walking through directories\"):\n",
    "    for filename in filenames:\n",
    "        file_path = os.path.join(dirname, filename)\n",
    "        if \"CloudLandsat_2020\" in dirname:\n",
    "            filenames_x_val.append(file_path)\n",
    "        elif \"Landsat-8_2020\" in dirname:\n",
    "            filenames_y_val.append(file_path)\n",
    "\n",
    "# Extract just the filenames (without path)\n",
    "names_x = [os.path.basename(f) for f in filenames_x_val]\n",
    "names_y = [os.path.basename(f) for f in filenames_y_val]\n",
    "\n",
    "# Sort both lists\n",
    "names_x.sort()\n",
    "names_y.sort()\n",
    "\n",
    "# Compare\n",
    "print(\"Total in X:\", len(names_x))\n",
    "print(\"Total in Y:\", len(names_y))\n",
    "\n",
    "# Show mismatches if any\n",
    "mismatches = set(names_x).symmetric_difference(set(names_y))\n",
    "if mismatches:\n",
    "    print(\"Mismatched filenames:\")\n",
    "    print(mismatches)\n",
    "else:\n",
    "    print(\"Filenames match perfectly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1326710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile as tiff\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def filter_valid_images(x_list, y_list):\n",
    "    valid_x = []\n",
    "    valid_y = []\n",
    "    \n",
    "    # Creamos un diccionario para búsqueda rápida (asumiendo que los nombres base coinciden)\n",
    "    # y vinculamos X con Y\n",
    "    for x_path, y_path in tqdm(zip(x_list, y_list), total=len(x_list), desc=\"Verificando archivos\"):\n",
    "        try:\n",
    "            # Intentamos abrir ambos archivos con tifffile\n",
    "            test_x = tiff.imread(x_path)\n",
    "            test_y = tiff.imread(y_path)\n",
    "            \n",
    "            # Si no falló, los agregamos a la lista definitiva\n",
    "            valid_x.append(x_path)\n",
    "            valid_y.append(y_path)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Saltando archivo corrupto o incompatible: {os.path.basename(x_path)}\")\n",
    "            \n",
    "    return valid_x, valid_y\n",
    "\n",
    "# Aplicar a Train\n",
    "filenames_x, filenames_y = filter_valid_images(filenames_x, filenames_y)\n",
    "# Aplicar a Val\n",
    "filenames_x_val, filenames_y_val = filter_valid_images(filenames_x_val, filenames_y_val)\n",
    "\n",
    "print(f\"✅ Archivos válidos para entrenamiento: {len(filenames_x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c090e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from torch.utils.data import Dataset\n",
    "import warnings\n",
    "\n",
    "class CloudRemovalDataset(Dataset):\n",
    "    def __init__(self, x_paths, y_paths, size=(1024, 1024), augment=False):\n",
    "        self.x_paths = x_paths\n",
    "        self.y_paths = y_paths\n",
    "        self.size = size\n",
    "        self.augment = augment\n",
    "\n",
    "        # Definimos las mismas aumentaciones del paper\n",
    "        self.transform = A.Compose([\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.VerticalFlip(p=0.5),\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.3),\n",
    "        ], additional_targets={'mask': 'image'})\n",
    "\n",
    "    def _load_tiff(self, path):\n",
    "        try:\n",
    "            with rasterio.open(path) as src:\n",
    "                # El paper lee bandas 3, 2, 1 (RGB para Landsat)\n",
    "                # rasterio devuelve (Bandas, H, W)\n",
    "                image = src.read([3, 2, 1]).astype(np.float32)\n",
    "                \n",
    "                # Transponemos a (H, W, Bandas) para OpenCV y Albumentations\n",
    "                image = np.transpose(image, (1, 2, 0))\n",
    "\n",
    "                # Manejo de NaNs como en el paper\n",
    "                if np.isnan(image).any():\n",
    "                    return None\n",
    "                \n",
    "                # Resize a la resolución del paper\n",
    "                image = cv2.resize(image, self.size, interpolation=cv2.INTER_LINEAR)\n",
    "                \n",
    "                # Normalización:\n",
    "                # Primero asegurar 0-1 (Landsat suele ser 16-bit o ya venir escalado)\n",
    "                if image.max() > 1.0:\n",
    "                    # Si es 16-bit usamos 65535, si es 8-bit usamos 255\n",
    "                    max_val = 65535.0 if image.max() > 255 else 255.0\n",
    "                    image = image / max_val\n",
    "                \n",
    "                # Rango [-1, 1] según el paper\n",
    "                image = (image * 2.0) - 1.0\n",
    "                return image\n",
    "                \n",
    "        except Exception as e:\n",
    "            warnings.warn(f\"Error leyendo {path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_img = self._load_tiff(self.x_paths[idx])\n",
    "        y_img = self._load_tiff(self.y_paths[idx])\n",
    "\n",
    "        # Si el archivo está corrupto o tiene NaNs, saltamos al siguiente\n",
    "        if x_img is None or y_img is None:\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "        if self.augment:\n",
    "            transformed = self.transform(image=x_img, mask=y_img)\n",
    "            x_img, y_img = transformed[\"image\"], transformed[\"mask\"]\n",
    "\n",
    "        # Convertir a Tensores (C, H, W)\n",
    "        x_tensor = torch.from_numpy(x_img).permute(2, 0, 1)\n",
    "        y_tensor = torch.from_numpy(y_img).permute(2, 0, 1)\n",
    "\n",
    "        return x_tensor, y_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b671959c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        def conv_block(in_c, out_c):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_c, out_c, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "\n",
    "        self.enc1 = conv_block(in_channels, 64)\n",
    "        self.enc2 = conv_block(64, 128)\n",
    "        self.enc3 = conv_block(128, 256)\n",
    "        self.enc4 = conv_block(256, 512)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = conv_block(512, 256)\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = conv_block(256, 128)\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = conv_block(128, 64)\n",
    "        \n",
    "        self.final = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s1 = self.enc1(x)\n",
    "        s2 = self.enc2(self.pool(s1))\n",
    "        s3 = self.enc3(self.pool(s2))\n",
    "        s4 = self.enc4(self.pool(s3))\n",
    "        \n",
    "        d3 = self.dec3(torch.cat([self.up3(s4), s3], dim=1))\n",
    "        d2 = self.dec2(torch.cat([self.up2(d3), s2], dim=1))\n",
    "        d1 = self.dec1(torch.cat([self.up1(d2), s1], dim=1))\n",
    "\n",
    "        out = self.final(d1)\n",
    "        return torch.tanh(out) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebe09de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CloudRemovalDataset(filenames_x, filenames_y, size=(256, 256), augment=True)\n",
    "val_ds = CloudRemovalDataset(filenames_x_val, filenames_y_val, size=(256, 256), augment=False)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=4)\n",
    "\n",
    "# Modelo, Optimización y Pérdida\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.L1Loss() # MAE Loss\n",
    "\n",
    "# Bucle de entrenamiento simplificado\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    print(f\"Loss: {train_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3443a2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics.image import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def denormalize(tensor):\n",
    "    \"\"\"Pasa de [-1, 1] a [0, 1] para visualización y métricas\"\"\"\n",
    "    return (tensor + 1.0) / 2.0\n",
    "\n",
    "def evaluate_and_visualize(model, val_loader, device, num_samples=3):\n",
    "    # ESPECIFICAR data_range=1.0 porque nuestras imágenes están en [0, 1]\n",
    "    psnr_metric = PeakSignalNoiseRatio(data_range=1.0).to(device)\n",
    "    ssim_metric = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
    "    mae_metric = torch.nn.L1Loss()\n",
    "    \n",
    "    model.eval()\n",
    "    total_psnr = 0\n",
    "    total_ssim = 0\n",
    "    total_mae = 0\n",
    "    \n",
    "    samples_shown = 0\n",
    "    \n",
    "    print(\"Iniciando evaluación...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            # Predicción\n",
    "            output = model(x)\n",
    "            \n",
    "            # Desnormalizar para métricas y visualización\n",
    "            output_dn = denormalize(output)\n",
    "            y_dn = denormalize(y)\n",
    "            x_dn = denormalize(x)\n",
    "            \n",
    "            # Calcular métricas del batch\n",
    "            total_psnr += psnr_metric(output_dn, y_dn).item()\n",
    "            total_ssim += ssim_metric(output_dn, y_dn).item()\n",
    "            total_mae += mae_metric(output_dn, y_dn).item()\n",
    "            \n",
    "            # Visualizar ejemplos\n",
    "            if samples_shown < num_samples:\n",
    "                fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "                \n",
    "                # Imagen con nubes (Input) - Clipping por seguridad para matplotlib\n",
    "                ax[0].imshow(x_dn[0].cpu().permute(1, 2, 0).numpy().clip(0, 1))\n",
    "                ax[0].set_title(\"Entrada (Con Nubes)\")\n",
    "                ax[0].axis('off')\n",
    "                \n",
    "                # Imagen generada (Predicción)\n",
    "                ax[1].imshow(output_dn[0].cpu().permute(1, 2, 0).numpy().clip(0, 1))\n",
    "                ax[1].set_title(\"Predicción (Cloud Removed)\")\n",
    "                ax[1].axis('off')\n",
    "                \n",
    "                # Imagen real limpia (Ground Truth)\n",
    "                ax[2].imshow(y_dn[0].cpu().permute(1, 2, 0).numpy().clip(0, 1))\n",
    "                ax[2].set_title(\"Real (Limpia)\")\n",
    "                ax[2].axis('off')\n",
    "                \n",
    "                plt.show()\n",
    "                samples_shown += 1\n",
    "                \n",
    "    # Promedios finales\n",
    "    avg_psnr = total_psnr / len(val_loader)\n",
    "    avg_ssim = total_ssim / len(val_loader)\n",
    "    avg_mae = total_mae / len(val_loader)\n",
    "    \n",
    "    print(f\"\\n--- Resultados de la Evaluación ---\")\n",
    "    print(f\"PSNR Medio: {avg_psnr:.2f} dB\")\n",
    "    print(f\"SSIM Medio: {avg_ssim:.4f}\")\n",
    "    print(f\"MAE Medio: {avg_mae:.4f}\")\n",
    "\n",
    "# Ejecutar evaluación\n",
    "evaluate_and_visualize(model, val_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767553f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.amp import autocast, GradScaler \n",
    "\n",
    "\n",
    "class CloudRemovalGuidedDataset(Dataset):\n",
    "    def __init__(self, x_paths, y_paths, seg_model, size=(256, 256)):\n",
    "        self.x_paths = x_paths\n",
    "        self.y_paths = y_paths\n",
    "        self.seg_model = seg_model\n",
    "        self.size = size\n",
    "        self.seg_model.eval() \n",
    "\n",
    "    def _load_tiff(self, path):\n",
    "        with rasterio.open(path) as src:\n",
    "            img = src.read([3, 2, 1]).astype(np.float32)\n",
    "            img = np.transpose(img, (1, 2, 0))\n",
    "            img = cv2.resize(img, self.size)\n",
    "            if img.max() > 1.0:\n",
    "                max_val = 65535.0 if img.max() > 255 else 255.0\n",
    "                img /= max_val\n",
    "            return (img * 2.0) - 1.0\n",
    "\n",
    "    def __len__(self): return len(self.x_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_img = self._load_tiff(self.x_paths[idx])\n",
    "        y_img = self._load_tiff(self.y_paths[idx])\n",
    "\n",
    "        x_tensor = torch.from_numpy(x_img).permute(2, 0, 1).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            mask_pred = self.seg_model(x_tensor)\n",
    "            \n",
    "            mask = (torch.sigmoid(mask_pred) > 0.5).float().squeeze(0).cpu()\n",
    "            if mask.dim() == 2: mask = mask.unsqueeze(0)\n",
    "\n",
    "        x_rgb = torch.from_numpy(x_img).permute(2, 0, 1)\n",
    "        \n",
    "        input_4ch = torch.cat([x_rgb, mask], dim=0)\n",
    "        \n",
    "        input_4ch = input_4ch[:4, :, :] \n",
    "        \n",
    "        target_3ch = torch.from_numpy(y_img).permute(2, 0, 1)\n",
    "\n",
    "        return input_4ch, target_3ch\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_cr = UNetCR(n_channels=4, n_classes=3).to(device)\n",
    "optimizer = torch.optim.Adam(model_cr.parameters(), lr=1e-4)\n",
    "criterion = nn.L1Loss()\n",
    "scaler = GradScaler('cuda') \n",
    "\n",
    "train_ds = CloudRemovalGuidedDataset(filenames_x, filenames_y, seg_model=model)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, drop_last=True)\n",
    "\n",
    "print(f\"Iniciando entrenamiento... Target input shape: [Batch, 4, {train_ds.size[0]}, {train_ds.size[1]}]\")\n",
    "\n",
    "for epoch in range(10):\n",
    "    model_cr.train()\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/10\")\n",
    "    \n",
    "    for x, y in pbar:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast('cuda'):\n",
    "            output = model_cr(x)\n",
    "            mask_w = x[:, 3:4, :, :]\n",
    "            loss = criterion(output, y) + (criterion(output * mask_w, y * mask_w) * 3.0)\n",
    "            \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': running_loss/len(train_loader)})\n",
    "\n",
    "print(\" Entrenamiento completado.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
