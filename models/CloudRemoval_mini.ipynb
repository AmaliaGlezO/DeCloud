{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e7fe07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "CLOUD REMOVAL - DIAGNÓSTICO DEL DATASET\n",
      "======================================================================\n",
      "\n",
      "Directorio de imágenes nubladas: ../data/temporal\n",
      "  Número de imágenes: 680\n",
      "  Primeras 5: ['118032_101.tif', '118032_102.tif', '118032_103.tif', '118032_104.tif', '118032_105.tif']\n",
      "\n",
      "Directorio de imágenes limpias: ../data/masked\n",
      "  Número de imágenes: 680\n",
      "  Primeras 5: ['118032_101.tif', '118032_102.tif', '118032_103.tif', '118032_104.tif', '118032_105.tif']\n",
      "\n",
      "✓ COINCIDENCIA: Mismo número de archivos (680)\n",
      "\n",
      "Verificando nombres de archivos:\n",
      "  ✓ 118032_101.tif <-> 118032_101.tif\n",
      "  ✓ 118032_102.tif <-> 118032_102.tif\n",
      "  ✓ 118032_103.tif <-> 118032_103.tif\n",
      "  ✓ 118032_104.tif <-> 118032_104.tif\n",
      "  ✓ 118032_105.tif <-> 118032_105.tif\n",
      "\n",
      "✓ Los nombres de archivo coinciden perfectamente\n",
      "\n",
      "======================================================================\n",
      "Dataset de entrenamiento: 680 pares de imágenes\n",
      "Tamaño de batch: 2\n",
      "Batches por época: 340\n",
      "\n",
      "======================================================================\n",
      "PRUEBA DEL PRIMER BATCH\n",
      "======================================================================\n",
      "Imágenes nubladas: torch.Size([2, 3, 256, 256])\n",
      "  Rango de valores: [-2.118, 2.640]\n",
      "\n",
      "Imágenes limpias: torch.Size([2, 3, 256, 256])\n",
      "  Rango de valores: [-2.101, 2.640]\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CloudRemovalDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset para Cloud Removal (Eliminación de Nubes)\n",
    "    - Input: Imagen con nubes\n",
    "    - Output: Imagen limpia (sin nubes)\n",
    "    \"\"\"\n",
    "    def __init__(self, cloudy_dir, clear_dir, size=(256, 256)):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cloudy_dir: Directorio con imágenes nubladas\n",
    "            clear_dir: Directorio con imágenes limpias (ground truth)\n",
    "            size: Tamaño de redimensionamiento\n",
    "        \"\"\"\n",
    "        self.cloudy_dir = cloudy_dir\n",
    "        self.clear_dir = clear_dir\n",
    "        self.size = size\n",
    "\n",
    "        # Obtener lista de archivos\n",
    "        self.cloudy_files = sorted([f for f in os.listdir(cloudy_dir) if f.endswith(('.tif', '.jpg', '.png'))])\n",
    "        self.clear_files = sorted([f for f in os.listdir(clear_dir) if f.endswith(('.tif', '.jpg', '.png'))])\n",
    "\n",
    "        # Transformaciones para ambas imágenes (misma normalización)\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(self.size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cloudy_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Rutas de imagen nublada y limpia\n",
    "        cloudy_path = os.path.join(self.cloudy_dir, self.cloudy_files[idx])\n",
    "        clear_path = os.path.join(self.clear_dir, self.clear_files[idx])\n",
    "\n",
    "        # Cargar imágenes\n",
    "        cloudy_image = Image.open(cloudy_path).convert('RGB')\n",
    "        clear_image = Image.open(clear_path).convert('RGB')\n",
    "\n",
    "        # Aplicar transformaciones\n",
    "        cloudy_tensor = self.transform(cloudy_image)\n",
    "        clear_tensor = self.transform(clear_image)\n",
    "\n",
    "        return cloudy_tensor, clear_tensor\n",
    "\n",
    "# ============================================\n",
    "# DIAGNÓSTICO Y CONFIGURACIÓN\n",
    "# ============================================\n",
    "print(\"=\" * 70)\n",
    "print(\"CLOUD REMOVAL - DIAGNÓSTICO DEL DATASET\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Crear dataset\n",
    "train_dataset = CloudRemovalDataset(\n",
    "    cloudy_dir=\"../data/masked\",      # Imágenes con nubes\n",
    "    clear_dir=\"../data/temporal\",         # Imágenes limpias\n",
    "    size=(256, 256)\n",
    ")\n",
    "\n",
    "# Verificar directorios\n",
    "print(f\"\\nDirectorio de imágenes nubladas: ../data/temporal\")\n",
    "print(f\"  Número de imágenes: {len(train_dataset.cloudy_files)}\")\n",
    "if len(train_dataset.cloudy_files) > 0:\n",
    "    print(f\"  Primeras 5: {train_dataset.cloudy_files[:5]}\")\n",
    "\n",
    "print(f\"\\nDirectorio de imágenes limpias: ../data/masked\")\n",
    "print(f\"  Número de imágenes: {len(train_dataset.clear_files)}\")\n",
    "if len(train_dataset.clear_files) > 0:\n",
    "    print(f\"  Primeras 5: {train_dataset.clear_files[:5]}\")\n",
    "\n",
    "# Verificar coincidencia\n",
    "if len(train_dataset.cloudy_files) == len(train_dataset.clear_files):\n",
    "    print(f\"\\n✓ COINCIDENCIA: Mismo número de archivos ({len(train_dataset)})\")\n",
    "else:\n",
    "    print(f\"\\n✗ ERROR: Diferente número de archivos!\")\n",
    "    print(f\"  Nubladas: {len(train_dataset.cloudy_files)}\")\n",
    "    print(f\"  Limpias: {len(train_dataset.clear_files)}\")\n",
    "\n",
    "# Verificar que los nombres coincidan\n",
    "print(\"\\nVerificando nombres de archivos:\")\n",
    "all_match = True\n",
    "for cloudy_file, clear_file in zip(train_dataset.cloudy_files[:5], train_dataset.clear_files[:5]):\n",
    "    match = \"✓\" if cloudy_file == clear_file else \"✗\"\n",
    "    print(f\"  {match} {cloudy_file} <-> {clear_file}\")\n",
    "    if cloudy_file != clear_file:\n",
    "        all_match = False\n",
    "\n",
    "if all_match and len(train_dataset.cloudy_files) > 0:\n",
    "    print(\"\\n✓ Los nombres de archivo coinciden perfectamente\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "\n",
    "# ============================================\n",
    "# DATALOADER\n",
    "# ============================================\n",
    "batch_size = 2\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"Dataset de entrenamiento: {len(train_dataset)} pares de imágenes\")\n",
    "print(f\"Tamaño de batch: {batch_size}\")\n",
    "print(f\"Batches por época: {len(train_dataset) // batch_size}\")\n",
    "print()\n",
    "\n",
    "# Probar un batch\n",
    "for cloudy_batch, clear_batch in train_loader:\n",
    "    print(\"=\" * 70)\n",
    "    print(\"PRUEBA DEL PRIMER BATCH\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Imágenes nubladas: {cloudy_batch.shape}\")\n",
    "    print(f\"  Rango de valores: [{cloudy_batch.min():.3f}, {cloudy_batch.max():.3f}]\")\n",
    "    print(f\"\\nImágenes limpias: {clear_batch.shape}\")\n",
    "    print(f\"  Rango de valores: [{clear_batch.min():.3f}, {clear_batch.max():.3f}]\")\n",
    "    print(\"=\" * 70)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4fbd31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_msssim as ms\n",
    "\n",
    "# ============================\n",
    "# BLOQUES BÁSICOS\n",
    "# ============================\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1)\n",
    "        self.norm = nn.BatchNorm2d(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = F.relu(self.norm(self.conv1(x)))\n",
    "        x = self.norm(self.conv2(x))\n",
    "        return F.relu(x + residual)\n",
    "\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, g_ch, x_ch, inter_ch):\n",
    "        super().__init__()\n",
    "        self.Wg = nn.Conv2d(g_ch, inter_ch, 1)\n",
    "        self.Wx = nn.Conv2d(x_ch, inter_ch, 1)\n",
    "        self.psi = nn.Conv2d(inter_ch, 1, 1)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        psi = torch.relu(self.Wg(g) + self.Wx(x))\n",
    "        psi = torch.sigmoid(self.psi(psi))\n",
    "        return x * psi\n",
    "\n",
    "\n",
    "# ============================\n",
    "# ENCODER / DECODER\n",
    "# ============================\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            ResidualBlock(out_ch)\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        p = self.pool(x)\n",
    "        return x, p\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_ch, out_ch, 2, stride=2)\n",
    "        self.att = AttentionBlock(out_ch, out_ch, out_ch//2)\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(out_ch*2, out_ch, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            ResidualBlock(out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, skip):\n",
    "        x = self.up(x)\n",
    "        skip = self.att(x, skip)\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "# ============================\n",
    "# MODELO FINAL\n",
    "# ============================\n",
    "\n",
    "class CloudRemovalNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d1 = Down(3, 32)\n",
    "        self.d2 = Down(32, 64)\n",
    "        self.d3 = Down(64, 128)\n",
    "        self.d4 = Down(128, 256)\n",
    "\n",
    "        self.bridge = nn.Sequential(\n",
    "            nn.Conv2d(256, 512, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            ResidualBlock(512)\n",
    "        )\n",
    "\n",
    "\n",
    "        self.u1 = Up(512, 256)\n",
    "        self.u2 = Up(256, 128)\n",
    "        self.u3 = Up(128, 64)\n",
    "        self.u4 = Up(64, 32)\n",
    "\n",
    "        self.out = nn.Conv2d(32, 3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        s1, p1 = self.d1(x)\n",
    "        s2, p2 = self.d2(p1)\n",
    "        s3, p3 = self.d3(p2)\n",
    "        s4, p4 = self.d4(p3)\n",
    "\n",
    "        b = self.bridge(p4)\n",
    "\n",
    "        x = self.u1(b, s4)\n",
    "        x = self.u2(x, s3)\n",
    "        x = self.u3(x, s2)\n",
    "        x = self.u4(x, s1)\n",
    "\n",
    "        return torch.tanh(self.out(x))  # salida normalizada\n",
    "\n",
    "class CloudLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.8):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.L1Loss()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        l1_loss = self.l1(pred, target)\n",
    "        ssim_loss = 1 - ms.ssim(pred, target, data_range=2.0, size_average=True)\n",
    "        return self.alpha * l1_loss + (1 - self.alpha) * ssim_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc50587",
   "metadata": {},
   "source": [
    "### correr en la nube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aba600c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amalia\\AppData\\Local\\Temp\\ipykernel_16304\\91141678.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "C:\\Users\\Amalia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\cuda\\amp\\grad_scaler.py:31: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  super().__init__(\n",
      "Epoch [1/100]:   0%|          | 0/170 [00:00<?, ?it/s]C:\\Users\\Amalia\\AppData\\Local\\Temp\\ipykernel_16304\\91141678.py:32: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "C:\\Users\\Amalia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\cuda\\amp\\autocast_mode.py:54: UserWarning: CUDA is not available or torch_xla is imported. Disabling autocast.\n",
      "  super().__init__(\n",
      "Epoch [1/100]:   1%|          | 2/170 [00:26<36:50, 13.16s/it, loss=0.988]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m     output \u001b[38;5;241m=\u001b[39m model(cloudy)\n\u001b[0;32m     34\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(output, clear)\n\u001b[1;32m---> 36\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m scaler\u001b[38;5;241m.\u001b[39mstep(optimizer)\n\u001b[0;32m     38\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_tensor.py:630\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    622\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    623\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    628\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    629\u001b[0m     )\n\u001b[1;32m--> 630\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\autograd\\__init__.py:364\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    359\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    361\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 364\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\autograd\\graph.py:865\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    863\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    864\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = CloudRemovalNet().to(device)\n",
    "criterion = CloudLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=50,\n",
    "    eta_min=1e-6\n",
    ")\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "\n",
    "    for cloudy, clear in loop:\n",
    "        cloudy = cloudy.to(device)\n",
    "        clear = clear.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output = model(cloudy)\n",
    "            loss = criterion(output, clear)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    # Guardar checkpoints\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        torch.save(model.state_dict(), f\"cloud_model_epoch_{epoch+1}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745e2ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1/60]: 100%|██████████| 340/340 [18:32<00:00,  3.27s/it, loss=0.899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 0.7775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2/60]: 100%|██████████| 340/340 [18:13<00:00,  3.22s/it, loss=0.547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Loss: 0.7299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3/60]: 100%|██████████| 340/340 [18:39<00:00,  3.29s/it, loss=0.719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Loss: 0.7207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4/60]:  35%|███▍      | 118/340 [07:17<11:00,  2.98s/it, loss=0.525]"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import os\n",
    "\n",
    "torch.set_num_threads(4)  \n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"4\"\n",
    "\n",
    "\n",
    "device = \"cpu\"   \n",
    "\n",
    "model = CloudRemovalNet().to(device)\n",
    "criterion = CloudLoss()\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=2e-4   # un poco mayor para CPU\n",
    ")\n",
    "\n",
    "# gradient accumulation para simular batch grande\n",
    "accum_steps = 4   \n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "\n",
    "    for i, (cloudy, clear) in enumerate(loop):\n",
    "        cloudy = cloudy.to(device)\n",
    "        clear = clear.to(device)\n",
    "\n",
    "        output = model(cloudy)\n",
    "        loss = criterion(output, clear)\n",
    "        loss = loss / accum_steps\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        if (i + 1) % accum_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item() * accum_steps\n",
    "        loop.set_postfix(loss=loss.item() * accum_steps)\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1} | Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save(model.state_dict(), f\"cloud_cpu_epoch_{epoch+1}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00c390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denorm(x):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(1,3,1,1).to(x.device)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(1,3,1,1).to(x.device)\n",
    "    return x * std + mean\n",
    "\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    cloudy, clear = next(iter(train_loader))\n",
    "    cloudy = cloudy.to(device)\n",
    "\n",
    "    pred = model(cloudy)\n",
    "\n",
    "    cloudy = denorm(cloudy)\n",
    "    pred = denorm(pred)\n",
    "    clear = denorm(clear.to(device))\n",
    "\n",
    "    fig, axs = plt.subplots(3,3, figsize=(9,9))\n",
    "    for i in range(3):\n",
    "        axs[i,0].imshow(cloudy[i].permute(1,2,0).cpu().clamp(0,1))\n",
    "        axs[i,1].imshow(pred[i].permute(1,2,0).cpu().clamp(0,1))\n",
    "        axs[i,2].imshow(clear[i].permute(1,2,0).cpu().clamp(0,1))\n",
    "\n",
    "        axs[i,0].set_title(\"Cloudy\")\n",
    "        axs[i,1].set_title(\"Predicted\")\n",
    "        axs[i,2].set_title(\"Clear\")\n",
    "\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
