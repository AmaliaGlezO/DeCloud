{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d63a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudTestDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, size=(256,256)):\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.size = size\n",
    "\n",
    "        self.files = sorted([\n",
    "            f for f in os.listdir(images_dir)\n",
    "            if f.endswith(('.tif'))\n",
    "        ])\n",
    "\n",
    "        self.img_tf = transforms.Compose([\n",
    "            transforms.Resize(size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485,0.456,0.406],\n",
    "                std=[0.229,0.224,0.225]\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.mask_tf = transforms.Compose([\n",
    "            transforms.Resize(size, interpolation=transforms.InterpolationMode.NEAREST),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: (x > 0.5).float())\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.files[idx]\n",
    "\n",
    "        image = Image.open(\n",
    "            os.path.join(self.images_dir, fname)\n",
    "        ).convert(\"RGB\")\n",
    "\n",
    "        mask = Image.open(\n",
    "            os.path.join(self.masks_dir, fname)\n",
    "        ).convert(\"L\")\n",
    "\n",
    "        return self.img_tf(image), self.mask_tf(mask), fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa7140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ================================\n",
    "# Dataset para test o inferencia\n",
    "# ================================\n",
    "class CloudTestDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, size=(256,256)):\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.size = size\n",
    "\n",
    "        # Solo archivos .tif\n",
    "        self.files = sorted([f for f in os.listdir(images_dir) if f.endswith('.tif')])\n",
    "\n",
    "        self.img_tf = transforms.Compose([\n",
    "            transforms.Resize(size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
    "        ])\n",
    "\n",
    "        self.mask_tf = transforms.Compose([\n",
    "            transforms.Resize(size, interpolation=transforms.InterpolationMode.NEAREST),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: (x > 0.5).float())\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.files[idx]\n",
    "\n",
    "        image = Image.open(os.path.join(self.images_dir, fname)).convert(\"RGB\")\n",
    "        mask = Image.open(os.path.join(self.masks_dir, fname)).convert(\"L\")\n",
    "\n",
    "        return self.img_tf(image), self.mask_tf(mask), fname\n",
    "\n",
    "# ================================\n",
    "# Dataset para entrenamiento de reconstrucción\n",
    "# ================================\n",
    "class CloudReconstructionDataset(Dataset):\n",
    "    def __init__(self, cloudy_dir, mask_dir, clean_dir, size=(256,256)):\n",
    "        self.cloudy_dir = cloudy_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.clean_dir = clean_dir\n",
    "        self.size = size\n",
    "\n",
    "        cloudy_files = set(os.listdir(cloudy_dir))\n",
    "        mask_files = set(os.listdir(mask_dir))\n",
    "        clean_files = set(os.listdir(clean_dir))\n",
    "\n",
    "        # Archivos comunes a las tres carpetas\n",
    "        self.files = sorted(list(cloudy_files & mask_files & clean_files))\n",
    "        if len(self.files) == 0:\n",
    "            raise RuntimeError(\"No hay archivos válidos en las tres carpetas\")\n",
    "\n",
    "        self.tf = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.files[idx]\n",
    "        cloudy_img = Image.open(os.path.join(self.cloudy_dir, fname)).convert(\"RGB\").resize(self.size)\n",
    "        mask_img = Image.open(os.path.join(self.mask_dir, fname)).convert(\"L\").resize(self.size)\n",
    "        clean_img = Image.open(os.path.join(self.clean_dir, fname)).convert(\"RGB\").resize(self.size)\n",
    "\n",
    "        return self.tf(cloudy_img), self.tf(mask_img), self.tf(clean_img)\n",
    "\n",
    "# ================================\n",
    "# Modelo de reconstrucción\n",
    "# ================================\n",
    "class TerrainReconstructor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        base = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.enc = nn.ModuleList(list(base.children()))\n",
    "\n",
    "        self.up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(512, 256, 4, 2, 1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 4, 2, 1), nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 3, 4, 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc[0:3](x)\n",
    "        e2 = self.enc[4](e1)\n",
    "        e3 = self.enc[5](e2)\n",
    "        e4 = self.enc[6](e3)\n",
    "        e5 = self.enc[7](e4)\n",
    "        return self.up(e5)\n",
    "\n",
    "# ================================\n",
    "# Pérdida de reconstrucción\n",
    "# ================================\n",
    "class ReconstructionLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.L1Loss()\n",
    "\n",
    "    def forward(self, generated, target):\n",
    "        return self.l1(generated, target)\n",
    "\n",
    "# ================================\n",
    "# Inicialización\n",
    "# ================================\n",
    "model_rec = TerrainReconstructor().to(device)\n",
    "optimizer_rec = torch.optim.Adam(model_rec.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "criterion_rec = ReconstructionLoss()\n",
    "\n",
    "# ================================\n",
    "# Entrenamiento\n",
    "# ================================\n",
    "def train_reconstruction(recon_loader, epochs=10):\n",
    "    model_rec.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for cloudy, mask, clean in recon_loader:\n",
    "            cloudy, mask, clean = cloudy.to(device), mask.to(device), clean.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred_mask = mask  # O usar tu modelo de máscara: model(cloudy)\n",
    "\n",
    "            outputs = model_rec(cloudy)\n",
    "            loss = criterion_rec(outputs, clean)\n",
    "\n",
    "            optimizer_rec.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_rec.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"[Recon] Epoch {epoch+1} Loss: {total_loss/len(recon_loader):.4f}\")\n",
    "\n",
    "# ================================\n",
    "# Ejemplo de uso\n",
    "# ================================\n",
    "# Dataset de reconstrucción\n",
    "recon_dataset = CloudReconstructionDataset(\"overall-mask\", \"masked\", \"temporal\")\n",
    "recon_loader = DataLoader(recon_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Entrenamiento\n",
    "train_reconstruction(recon_loader, epochs=5)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
