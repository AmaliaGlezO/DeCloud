{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13137649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device available: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbcfe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBlock(nn.Module):\n",
    "    \"\"\"Módulo de Atención para filtrar características irrelevantes\"\"\"\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * psi\n",
    "\n",
    "class CloudAttentionUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CloudAttentionUNet, self).__init__()\n",
    "        \n",
    "        base_model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.encoder0 = nn.Sequential(*list(base_model.children())[:3])\n",
    "        self.encoder1 = base_model.layer1\n",
    "        self.encoder2 = base_model.layer2\n",
    "        self.encoder3 = base_model.layer3\n",
    "        self.encoder4 = base_model.layer4\n",
    "\n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, 3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.att4 = AttentionBlock(F_g=512, F_l=512, F_int=256)\n",
    "        self.att3 = AttentionBlock(F_g=256, F_l=256, F_int=128)\n",
    "        self.att2 = AttentionBlock(F_g=128, F_l=128, F_int=64)\n",
    "        self.att1 = AttentionBlock(F_g=64, F_l=64, F_int=32)\n",
    "\n",
    "        self.up4 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
    "        self.up3 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
    "        self.up2 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.up1 = nn.ConvTranspose2d(64, 64, 2, stride=2)\n",
    "        \n",
    "        self.out_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e0 = self.encoder0(x)\n",
    "        e1 = self.encoder1(e0)\n",
    "        e2 = self.encoder2(e1)\n",
    "        e3 = self.encoder3(e2)\n",
    "        e4 = self.encoder4(e3)\n",
    "\n",
    "        b = self.bottleneck(e4)\n",
    "\n",
    "        d4 = self.up4(b)\n",
    "        x4 = self.att4(g=d4, x=e3)\n",
    "        \n",
    "        d3 = self.up3(d4)\n",
    "        x3 = self.att3(g=d3, x=e2)\n",
    "        \n",
    "        d2 = self.up2(d3)\n",
    "        x2 = self.att2(g=d2, x=e1)\n",
    "        \n",
    "        d1 = self.up1(d2)\n",
    "        x1 = self.att1(g=d1, x=e0)\n",
    "        \n",
    "        out = self.out_conv(d1)\n",
    "        out = F.interpolate(out, size=x.shape[2:], mode='bilinear', align_corners=True)\n",
    "        return torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969ee9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CloudTestDataset(Dataset):\n",
    "    def __init__(self, images_dir, masks_dir, size=(256,256)):\n",
    "        self.images_dir = images_dir\n",
    "        self.masks_dir = masks_dir\n",
    "        self.size = size\n",
    "\n",
    "        self.files = sorted([\n",
    "            f for f in os.listdir(images_dir)\n",
    "            if f.endswith(('.png','.jpg','.jpeg','.tif'))\n",
    "        ])\n",
    "\n",
    "        self.img_tf = transforms.Compose([\n",
    "            transforms.Resize(size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485,0.456,0.406],\n",
    "                std=[0.229,0.224,0.225]\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.mask_tf = transforms.Compose([\n",
    "            transforms.Resize(size, interpolation=transforms.InterpolationMode.NEAREST),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(lambda x: (x > 0.5).float())\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fname = self.files[idx]\n",
    "\n",
    "        image = Image.open(\n",
    "            os.path.join(self.images_dir, fname)\n",
    "        ).convert(\"RGB\")\n",
    "\n",
    "        mask = Image.open(\n",
    "            os.path.join(self.masks_dir, fname)\n",
    "        ).convert(\"L\")\n",
    "\n",
    "        return self.img_tf(image), self.mask_tf(mask), fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f30fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar directorios\n",
    "test_img_dir = \"overall-mask_test\"\n",
    "test_mask_dir = \"masked_test\"\n",
    "\n",
    "if not os.path.exists(test_img_dir):\n",
    "    raise FileNotFoundError(f\"❌ Directorio de imágenes no encontrado: {test_img_dir}\")\n",
    "if not os.path.exists(test_mask_dir):\n",
    "    raise FileNotFoundError(f\"❌ Directorio de máscaras no encontrado: {test_mask_dir}\")\n",
    "\n",
    "print(f\"✓ Directorio de imágenes: {test_img_dir}\")\n",
    "print(f\"✓ Directorio de máscaras: {test_mask_dir}\")\n",
    "\n",
    "test_dataset = CloudTestDataset(\n",
    "    images_dir=test_img_dir,\n",
    "    masks_dir=test_mask_dir,\n",
    "    size=(256, 256)\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"✓ Dataset cargado con {len(test_dataset)} imágenes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ade8f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "model_path = \"cloud_segmentation_model.pth\"\n",
    "\n",
    "if not os.path.exists(model_path):\n",
    "    raise FileNotFoundError(f\"❌ Archivo de modelo no encontrado: {model_path}\")\n",
    "\n",
    "model = CloudAttentionUNet().to(device)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "print(f\"✓ Modelo cargado desde: {model_path}\")\n",
    "print(f\"✓ Modelo en modo evaluación\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f72752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def dice_score(pred, target):\n",
    "    pred = pred.astype(bool)\n",
    "    target = target.astype(bool)\n",
    "    inter = np.logical_and(pred, target).sum()\n",
    "    return 2*inter / (pred.sum() + target.sum() + 1e-8)\n",
    "\n",
    "def iou_score(pred, target):\n",
    "    pred = pred.astype(bool)\n",
    "    target = target.astype(bool)\n",
    "    inter = np.logical_and(pred, target).sum()\n",
    "    union = np.logical_or(pred, target).sum()\n",
    "    return inter / (union + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46878dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dice = []\n",
    "all_iou = []\n",
    "results_summary = []\n",
    "\n",
    "print(f\"Evaluando {len(test_dataset)} imágenes...\\n\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (images, masks, fname) in enumerate(test_loader):\n",
    "        try:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Asegurar que tenemos la dimensión correcta\n",
    "            preds = outputs.squeeze() if outputs.shape[1] == 1 else outputs\n",
    "            preds = torch.sigmoid(preds) if preds.max() > 1 else preds\n",
    "            preds_np = preds.cpu().numpy()\n",
    "            \n",
    "            # Manejar dimensiones\n",
    "            if preds_np.ndim == 3:\n",
    "                preds_np = preds_np[0]\n",
    "            \n",
    "            masks_np = masks.squeeze().cpu().numpy()\n",
    "            binary_pred = (preds_np > 0.5).astype(\"float32\")\n",
    "\n",
    "            # Métricas\n",
    "            dice = dice_score(binary_pred, masks_np)\n",
    "            iou = iou_score(binary_pred, masks_np)\n",
    "\n",
    "            all_dice.append(dice)\n",
    "            all_iou.append(iou)\n",
    "            results_summary.append({\n",
    "                'filename': fname[0],\n",
    "                'dice': dice,\n",
    "                'iou': iou\n",
    "            })\n",
    "\n",
    "            # ===== Mostrar resultados =====\n",
    "            img_np = images.cpu().numpy()[0].transpose(1, 2, 0)\n",
    "\n",
    "            # Desnormalizar para visualizar\n",
    "            mean = np.array([0.485, 0.456, 0.406])\n",
    "            std = np.array([0.229, 0.224, 0.225])\n",
    "            img_np = (img_np * std + mean).clip(0, 1)\n",
    "\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "            axes[0].imshow(img_np)\n",
    "            axes[0].set_title(f\"Imagen\\n{fname[0]}\")\n",
    "            axes[0].axis(\"off\")\n",
    "\n",
    "            axes[1].imshow(masks_np, cmap=\"gray\")\n",
    "            axes[1].set_title(\"Máscara Real\")\n",
    "            axes[1].axis(\"off\")\n",
    "\n",
    "            axes[2].imshow(binary_pred, cmap=\"gray\")\n",
    "            axes[2].set_title(f\"Predicción\\nDice: {dice:.4f} | IoU: {iou:.4f}\")\n",
    "            axes[2].axis(\"off\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            print(f\"[{batch_idx+1}/{len(test_dataset)}] {fname[0]}: Dice={dice:.4f}, IoU={iou:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error procesando {fname[0]}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RESULTADOS PROMEDIO\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Dice promedio: {np.mean(all_dice):.4f} (±{np.std(all_dice):.4f})\")\n",
    "print(f\"IoU promedio:  {np.mean(all_iou):.4f} (±{np.std(all_iou):.4f})\")\n",
    "print(f\"Total de imágenes procesadas: {len(all_dice)}\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
